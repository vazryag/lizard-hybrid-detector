{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05760e9",
   "metadata": {},
   "source": [
    "# Feature Extraction Notebook\n",
    "In this notebook I'm using a pre-trained MobileNetV2 to extract features from the 3D image dataset.\n",
    "\n",
    "**Author**: Arthur G.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad801c",
   "metadata": {},
   "source": [
    "## Loading Dependencies\n",
    "In this section I'm loading and setting up the dependencies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7733b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing as t\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy.typing import NDArray\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNetV3Small\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "\n",
    "seed = 42\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9277ff1d",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "In this section I'm writing a set of helper functions to automate feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1f5233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_model_fn(base_model: t.Any) -> Model:\n",
    "    \"\"\"\n",
    "    Add a GlobalAveragePooling2D layer at the end of the\n",
    "    feature extractor.\n",
    "    \"\"\"\n",
    "    x = base_model.layers[-1].output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    return Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "def feature_extract(\n",
    "    dataset: NDArray[t.Any],\n",
    "    model: Model,\n",
    "    preprocess_fn: t.Any,\n",
    "    num_processes: int = 8\n",
    ") -> NDArray[t.Any]:\n",
    "    \"\"\"\n",
    "    Perform feature extraction on a numpy dataset of image matrices in parallel.\n",
    "    \"\"\"\n",
    "    preprocessed_images = preprocess_fn(dataset)\n",
    "    features = np.squeeze(model.predict(preprocessed_images))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5264957",
   "metadata": {},
   "source": [
    "## Loading Dataset\n",
    "In this section I'm loading the augmented image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d20f5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(os.path.join(\"..\", \"data\", \"processed\", \"augmented_image_dataset.npz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05075bb5",
   "metadata": {},
   "source": [
    "## Image Feature Extraction\n",
    "In this section I'm using the choosen pre-trained models to extract features from the augmented image dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5316ae31",
   "metadata": {},
   "source": [
    "### Defining Feature Extraction Models\n",
    "In this subsection I'm defining the feature extraction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50be1859",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"weights\": \"imagenet\", \"include_top\": False, \"input_shape\": (224, 224, 3)}\n",
    "\n",
    "# feature extraction models definition\n",
    "v1_model = feature_extraction_model_fn(base_model=MobileNet(**model_params))\n",
    "v2_model = feature_extraction_model_fn(base_model=MobileNetV2(**model_params))\n",
    "v3_large_model = feature_extraction_model_fn(base_model=MobileNetV3Large(**model_params))\n",
    "v3_small_model = feature_extraction_model_fn(base_model=MobileNetV3Small(**model_params))\n",
    "\n",
    "# preprocessing functions definition\n",
    "v1_preproc_fn = tf.keras.applications.mobilenet.preprocess_input\n",
    "v2_preproc_fn = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "v3_preproc_fn = tf.keras.applications.mobilenet_v3.preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abca3d1",
   "metadata": {},
   "source": [
    "### MobileNet V1\n",
    "Extracting features with MobileNet V1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82f60f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 43s 346ms/step\n",
      "36/36 [==============================] - 12s 344ms/step\n",
      "21/21 [==============================] - 7s 327ms/step\n"
     ]
    }
   ],
   "source": [
    "v1_train = feature_extract(dataset[\"train_images\"], model=v1_model, preprocess_fn=v1_preproc_fn)\n",
    "v1_test = feature_extract(dataset[\"test_images\"], model=v1_model, preprocess_fn=v1_preproc_fn)\n",
    "v1_valid = feature_extract(dataset[\"validation_images\"], model=v1_model, preprocess_fn=v1_preproc_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3258bb6f",
   "metadata": {},
   "source": [
    "### MobileNet V2\n",
    "Extracting features with MobileNet V2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "287e0350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 53s 425ms/step\n",
      "36/36 [==============================] - 15s 416ms/step\n",
      "21/21 [==============================] - 9s 404ms/step\n"
     ]
    }
   ],
   "source": [
    "v2_train = feature_extract(dataset[\"train_images\"], model=v2_model, preprocess_fn=v2_preproc_fn)\n",
    "v2_test = feature_extract(dataset[\"test_images\"], model=v2_model, preprocess_fn=v2_preproc_fn)\n",
    "v2_valid = feature_extract(dataset[\"validation_images\"], model=v2_model, preprocess_fn=v2_preproc_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b717e1",
   "metadata": {},
   "source": [
    "### MobileNet V3 Large\n",
    "Extracting features with MobileNet V3 Large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ea7215a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 55s 446ms/step\n",
      "36/36 [==============================] - 16s 446ms/step\n",
      "21/21 [==============================] - 9s 432ms/step\n"
     ]
    }
   ],
   "source": [
    "v3_large_train = feature_extract(dataset[\"train_images\"], model=v3_large_model, preprocess_fn=v3_preproc_fn)\n",
    "v3_large_test = feature_extract(dataset[\"test_images\"], model=v3_large_model, preprocess_fn=v3_preproc_fn)\n",
    "v3_large_valid = feature_extract(dataset[\"validation_images\"], model=v3_large_model, preprocess_fn=v3_preproc_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fc2c27",
   "metadata": {},
   "source": [
    "### MobileNet V3 Small\n",
    "Extracting features with MobileNet V3 Small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd8b62f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122/122 [==============================] - 25s 197ms/step\n",
      "36/36 [==============================] - 7s 191ms/step\n",
      "21/21 [==============================] - 4s 193ms/step\n"
     ]
    }
   ],
   "source": [
    "v3_small_train = feature_extract(dataset[\"train_images\"], model=v3_small_model, preprocess_fn=v3_preproc_fn)\n",
    "v3_small_test = feature_extract(dataset[\"test_images\"], model=v3_small_model, preprocess_fn=v3_preproc_fn)\n",
    "v3_small_valid = feature_extract(dataset[\"validation_images\"], model=v3_small_model, preprocess_fn=v3_preproc_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a917b4",
   "metadata": {},
   "source": [
    "### Serializing Augmented Dataset Features\n",
    "In this subsection I'm serializing the augmented dataset's extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b2378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\n",
    "    os.path.join(\"..\", \"data\", \"finalized\", \"augmented_images_features_dataset.npz\"),\n",
    "    v1_train_features=v1_train,\n",
    "    v1_test_features=v1_test,\n",
    "    v1_valid_features=v1_valid,\n",
    "    v2_train_features=v2_train,\n",
    "    v2_test_features=v2_test,\n",
    "    v2_valid_features=v2_valid,\n",
    "    v3_large_train_features=v3_large_train,\n",
    "    v3_large_test_features=v3_large_test,\n",
    "    v3_large_valid_features=v3_large_valid,\n",
    "    v3_small_train_features=v3_small_train,\n",
    "    v3_small_test_features=v3_small_test,\n",
    "    v3_small_valid_features=v3_small_valid,\n",
    "    train_targets=dataset[\"train_targets\"],\n",
    "    test_targets=dataset[\"test_targets\"],\n",
    "    validation_targets=dataset[\"validation_targets\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d29d19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
